{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "276dc24c-a03a-4f02-923b-4963f2307572",
   "metadata": {},
   "source": [
    "# FT用データ生成スクリプト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "683a8852-50c8-4ba2-a611-589ebd76bc9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !conda install -y -c conda-forge kalpy \\\n",
    "# kaldi \\\n",
    "# pynini \\\n",
    "# sox \\\n",
    "# ffmpeg \\\n",
    "# portaudio\n",
    "\n",
    "# # パッケージインストール\n",
    "# !cd /nfs1/s1f102201582/projects/fish-speech && \\\n",
    "# pip install -e .[cu128]\n",
    "# !pip install -r /nfs1/s1f102201582/projects/mhcc-moshi/moshi/generate_data/requirements.fs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69a5268f-a2e3-48e3-ab2a-54e9e5e298e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # mfa\n",
    "# # 日本語辞書のダウンロード\n",
    "# !mfa model download dictionary japanese_mfa\n",
    "\n",
    "# # 日本語音響モデルのダウンロード\n",
    "# !mfa model download acoustic japanese_mfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1666ef7b-1012-47c3-9229-6082e2d04f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join, expanduser\n",
    "from typing import Literal\n",
    "from glob import glob\n",
    "import shutil\n",
    "import ast\n",
    "import asyncio\n",
    "import random\n",
    "import subprocess\n",
    "import json\n",
    "import re\n",
    "import functools\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# .envファイル読み込み\n",
    "load_dotenv(\"/users/s1f102201582/projects/mhcc-moshi/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c9174e-0543-4b40-b3e3-7b26462d10c4",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "473c6dfd-9d4d-4bac-904a-df31dcd1a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "BASE_URL = \"https://api.openai.iniad.org/api/v1\"\n",
    "MODEL='gemini-2.5-flash'\n",
    "TEMPERATURE = 1.0\n",
    "\n",
    "cuda_devices = [0, 1, 2, 3]\n",
    "\n",
    "# 生成する音声のサンプリングレート\n",
    "setting_sr = 16000\n",
    "\n",
    "#対話音声データの個数を指定\n",
    "gen_dial_num = 1950\n",
    "\n",
    "# 非同期で同時に生成するデータの最大数\n",
    "MAX_SEMAPHORE = 12\n",
    "\n",
    "# すでに作成した対話データを削除するかどうか\n",
    "IS_REMOVE_EXIST_FILE = False\n",
    "\n",
    "# tempファイルを削除するかどうか\n",
    "IS_REMOVE_TMP = False\n",
    "\n",
    "# エラーが起きたときの最大試行回数\n",
    "MAX_RETRIES = 5\n",
    "\n",
    "version = \"fs/v1\"\n",
    "\n",
    "home_dir = expanduser(\"~\")\n",
    "# ftに使うjsonとaudioの出力フォルダパス\n",
    "json_dir_path = join(home_dir, \"projects/mhcc-moshi/moshi/data\", version, \"data_stereo\")\n",
    "audio_dir_path = join(home_dir, \"projects/mhcc-moshi/moshi/data\", version, \"data_stereo\")\n",
    "\n",
    "# tempフォルダまでのパス\n",
    "temp_dir_path = join(home_dir, \"projects/mhcc-moshi/moshi/data\", version, \"temp\")\n",
    "\n",
    "# mfa関連のパス\n",
    "model_dir = join(home_dir, \"Documents/MFA/pretrained_models/acoustic/japanese_mfa.zip\")\n",
    "mfa_input_dir = join(temp_dir_path, \"mfa_input\")\n",
    "mfa_output_dir = join(temp_dir_path, \"mfa_output\")\n",
    "\n",
    "# fish-speech関連のパス\n",
    "fs_tmp_path = join(temp_dir_path, \"fs\")\n",
    "\n",
    "#RAGで読み取るPDFのパス\n",
    "rag_pdf_dir = join(home_dir, \"projects/mhcc-moshi/mental_docs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537fbb1b-eb81-457b-a28c-9b49b30bf4a9",
   "metadata": {},
   "source": [
    "## フォルダ初期化 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf8bffea-83d1-44b8-9e3d-0bd71321ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = [\n",
    "    json_dir_path,\n",
    "    audio_dir_path,\n",
    "]\n",
    "\n",
    "temp_paths = [\n",
    "    fs_tmp_path,\n",
    "    mfa_input_dir,\n",
    "    mfa_output_dir,\n",
    "]\n",
    "\n",
    "def delete_files(dir_path):\n",
    "    shutil.rmtree(dir_path)\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "# フォルダがない場合、新規作成\n",
    "for p in [*data_paths, *temp_paths]:\n",
    "    if not os.path.isdir(p):\n",
    "        os.makedirs(p)\n",
    "\n",
    "# IS_REMOVE_TMPがtrueの場合、tempファイルを削除\n",
    "if IS_REMOVE_TMP:\n",
    "    delete_files(temp_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dce0734b-6cb1-4ce1-8134-ad238731b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_cuda_visible_devices = \"\"\n",
    "for i in cuda_devices:\n",
    "    os_cuda_visible_devices += str(i) + \",\"\n",
    "os_cuda_visible_devices = os_cuda_visible_devices[:-1]\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = os_cuda_visible_devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e391c-3079-4a7f-8eeb-e122e07f6707",
   "metadata": {},
   "source": [
    "## テキスト対話データ生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbc14b9b-7981-4975-a07b-16114cf7b3af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model定義\n",
    "model = ChatGoogleGenerativeAI(\n",
    "                 model=MODEL,\n",
    "                 temperature=TEMPERATURE)\n",
    "\n",
    "# 埋め込みモデル定義\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    openai_api_base=BASE_URL,\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "# データベース定義\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"collection\",\n",
    "    embedding_function=embeddings,\n",
    "    # persist_directory = \"/path/to/db_file\" # if necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97a271ae-62d4-44d1-b10d-8a8e38796ad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                     | 0/3 [00:00<?, ?it/s]Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(\n",
    "    rag_pdf_dir,\n",
    "    glob=\"*.pdf\",\n",
    "    show_progress=True,\n",
    "    loader_cls=PDFMinerLoader,\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"Loaded {len(docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "669019e5-a634-40d8-b0f8-31abe0fb4877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Debug\n",
    "# for doc in docs:\n",
    "#     print(\"-------------------------------------------------\")\n",
    "#     print(doc.metadata)\n",
    "#     print(len(doc.page_content))\n",
    "#     print(doc.page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ff84496-9aa7-45d9-89d3-3b8cde22fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#読み込んだ文章データをオーバーラップ200文字で1000文字づつ分割\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True, # 分割前の文章のインデックスを追跡\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# データベースにデータを追加\n",
    "document_ids = vector_store.add_documents(documents=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "757916d2-87c6-4033-8a23-02f0eaa6b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1].text\n",
    "    retrieved_docs = vector_store.similarity_search(last_query, k=2)\n",
    "\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. Use the following context in your response:\"\n",
    "        f\"\\n\\n{docs_content}\"\n",
    "    )\n",
    "\n",
    "    return system_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d58e3775-2aad-4363-b893-f7d74f62d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dialogue(BaseModel):\n",
    "    \"\"\"対話データを構成する対話クラス\"\"\"\n",
    "    speaker: Literal[\"A\", \"B\"] = Field(..., description=\"話者。Aはカウンセラー、Bはクライエントを表す。\")\n",
    "    raw_text: str = Field(..., description=\"FishAudioタグなしの話者が話した内容。\")\n",
    "    tag_text: str = Field(..., description=\"FishAudioタグありの話者が話した内容\")\n",
    "\n",
    "class Dialogues(BaseModel):\n",
    "    \"\"\"カウンセリングを目的としたカウンセリング対話データ\"\"\"\n",
    "    dialogues: list[Dialogue] = Field(..., description=\"対話データを構成する対話クラスのリスト。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c850f79b-c9ac-4722-b165-481de934e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model, \n",
    "    tools=[],\n",
    "    middleware=[prompt_with_context],\n",
    "    response_format=ToolStrategy(\n",
    "        Dialogues,\n",
    "        handle_errors=\"フォーマットに合うように、もう一度対話データを生成してください。\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "261f3908-86f7-4ddb-9565-c7b56e25632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#promptを作成\n",
    "prompt_template = \"\"\"あなたは、Fish Audioによる音声合成（TTS）用の対話シナリオを作成するプロのライターです。\n",
    "以下の【要件】、【設定】、そして【指示】に従い、対話データ（Dialogues）を生成してください。\n",
    "\n",
    "### 【目的】\n",
    "メンタルヘルスケアのカウンセリング対話をシミュレーションします。\n",
    "\n",
    "### 【出力データ構造の定義】\n",
    "* **speaker**: \"A\" (カウンセラー) または \"B\" (クライエント)\n",
    "* **tag_text**: 文頭に必ずFish Audio用マーカー（例: `(sad)`) を付与したテキスト。\n",
    "* **raw_text**: `tag_text`からマーカーを削除した純粋なテキスト。\n",
    "\n",
    "### 【最重要要件：自然な会話の再現】\n",
    "1.  **短いターン:** 一度の発話は短く区切る。長い独白は禁止。\n",
    "2.  **インターラプト:** Bが長く話そうとしたら、Aが「(listening)うんうん」と短い相槌で挟む。\n",
    "3.  **タグの使用:** 文頭に必ずタグをつける。\n",
    "\n",
    "### 【禁止事項】\n",
    "* **プレースホルダーの禁止:** テキスト中に「〇〇さん」「××さん」のような伏せ字・プレースホルダーを含めることは**厳禁**です。\n",
    "* **カウンセラーの「知ったかぶり」禁止:** カウンセラー(A)が、クライアント(B)が口にする前に、前回の内容や宿題について言及することを禁止します。文脈は必ずBの発言によって作ってください。\n",
    "\n",
    "### 【指示】\n",
    "\n",
    "1.  **会話の開始と導入フェーズ（最重要）:**\n",
    "    * **基本ルール:** カウンセラー(A)は、クライアント(B)の現在の状況や前回の詳細を**忘れている/知らない**ものとして振る舞ってください。\n",
    "    \n",
    "    * **状況が「初回」の場合:**\n",
    "        * A: まず**名前**を尋ねる。 -> B: **具体的な苗字**（佐藤、鈴木など）を名乗る。\n",
    "        * A: 「今日はどのようなことでお見えになりましたか？」と**来談理由**を尋ねる。\n",
    "        * B: 指定された**【トピック】**についての悩みを話し始める。\n",
    "        \n",
    "    * **状況が「初回」以外の場合:**\n",
    "        * A: 名前は呼ばずに挨拶し、「前回からいかがですか？」や「今日はどのようなお話をしましょうか？」と**完全にオープンな質問**をする。（※「宿題はどうでしたか？」などとAから特定の話題を振ることは禁止）。\n",
    "        * B: Aの質問に答える形で、**【トピック】**や**【状況】**（宿題があったことや、前回の続きなど）を**自分から説明する**。\n",
    "        * A: Bの説明を聞いて初めて、「ああ、そうでしたね」や「なるほど、そういう状況なのですね」と状況を把握・確認する。\n",
    "\n",
    "    * **共通事項:**\n",
    "        * AがBの話を聞いて状況を把握した**後**に、初めて具体的なカウンセリングへ移行してください。\n",
    "        * 導入のヒアリング段階であっても、「短いターン」と「インターラプト」のルールは守ってください。\n",
    "\n",
    "2.  **設定:**\n",
    "    * クライアント(B)のペルソナ: {selected_persona}\n",
    "    * トピック: {selected_topic}\n",
    "    * 状況: {selected_situation}\n",
    "    * 話し方指示: {selected_style_instruction}\n",
    "\n",
    "3.  **会話の構成:**\n",
    "    * 会話量は **4分程度** を目安とし、**25〜35往復（ターン）** 程度生成してください。\n",
    "    * ペルソナの背景（年齢・職業）を反映させる（直接言わせず、内容で匂わせる）。\n",
    "    * クライアント(B)の話し方指示（よどみ具合など）を忠実に守る。\n",
    "\n",
    "出力は指定された `Dialogues` スキーマに従ってください。\n",
    "\"\"\"\n",
    "\n",
    "# トピックリスト（悩みの種類）(全40項目)\n",
    "topic_list = [\n",
    "  # 仕事・キャリア関連\n",
    "  \"仕事のプレッシャーや過労、バーンアウト\",\n",
    "  \"職場の人間関係（上司、同僚、部下）\",\n",
    "  \"キャリアプランの悩み、キャリアチェンジの不安\",\n",
    "  \"転職・就職活動のストレス\",\n",
    "  \"ハラスメント（パワハラ、モラハラなど）の影響\",\n",
    "  \"仕事へのモチベーション低下、やる気が出ない\",\n",
    "\n",
    "  # 自己認識・感情関連\n",
    "  \"自己肯定感の低さ、自分を責めてしまう\",\n",
    "  \"完璧主義、失敗への過度な恐れ\",\n",
    "  \"他人の評価が過度に気になる、承認欲求\",\n",
    "  \"劣等感（他人との比較）\",\n",
    "  \"自分のやりたいことが分からない、アイデンティティの悩み\",\n",
    "  \"感情のコントロールが難しい（怒り、イライラ、悲しみ）\",\n",
    "  \"ネガティブ思考の癖、反芻思考（同じことをぐるぐる考えてしまう）\",\n",
    "  \"焦燥感、何かに追われている感覚\",\n",
    "  \"罪悪感（休むことへの罪悪感など）\",\n",
    "  \"虚無感、むなしさ、生きがいを感じられない\",\n",
    "  \"趣味や楽しみを感じられない（アンヘドニア）\",\n",
    "  \n",
    "  # 対人関係\n",
    "  \"家族関係（親子、夫婦、兄弟、親戚）\",\n",
    "  \"友人関係や恋愛関係の悩み\",\n",
    "  \"コミュニケーションへの苦手意識（雑談、会議での発言など）\",\n",
    "  \"人に頼ることができない、甘えられない\",\n",
    "  \"他人の期待に応えすぎようとしてしまう（ピープルプリーザー）\",\n",
    "  \"境界線（バウンダリー）の問題（NOと言えない）\",\n",
    "  \"孤独感、疎外感\",\n",
    "  \"HSP（繊細さ）に関する悩み\",\n",
    "  \n",
    "  # 生活・健康関連\n",
    "  \"将来への漠然とした不安\",\n",
    "  \"気分の落ち込み、無気力\",\n",
    "  \"睡眠に関する悩み（寝付けない、途中で起きる、過眠）\",\n",
    "  \"生活リズムの乱れ\",\n",
    "  \"体調不良（頭痛、倦怠感、腹痛など）と気分の関連\",\n",
    "  \"健康不安（病気への過度な心配）\",\n",
    "\n",
    "  # 習慣・行動関連\n",
    "  \"決断疲れ、何かを選ぶことができない\",\n",
    "  \"先延ばし癖、物事が始められない\",\n",
    "  \"SNS疲れ、デジタルデトックスの必要性\",\n",
    "\n",
    "  # 特定の出来事\n",
    "  \"ライフイベント（引っ越し、結婚、出産、育児、介護）に伴うストレス\",\n",
    "  \"特定の出来事による軽いトラウマやフラッシュバック\",\n",
    "  \"喪失体験（別れ、死別）からの回復（グリーフケア）\",\n",
    "  \"過去の選択への後悔\"\n",
    "]\n",
    "\n",
    "# 状況リスト（セッションの場面）\n",
    "situation_list = [\n",
    "  \"初回\",\n",
    "  \"初期\",\n",
    "  \"中期（深掘り）\",\n",
    "  \"中期（宿題の確認）\",\n",
    "  \"中期（感情の表出）\",\n",
    "  \"後期\",\n",
    "  \"終了（終結）\"\n",
    "]\n",
    "\n",
    "# クライアントのペルソナリスト（年齢と職業/立場のみ）\n",
    "persona_list = [\n",
    "    \"20代・会社員\",\n",
    "    \"30代・会社員\",\n",
    "    \"40代・会社員\",\n",
    "    \"50代・会社員\",\n",
    "    \"20代・大学生\",\n",
    "    \"20代・大学院生\",\n",
    "    \"30代・管理職\",\n",
    "    \"40代・主婦/主夫\",\n",
    "    \"30代・フリーランス\",\n",
    "    \"20代・アルバイト\",\n",
    "    \"40代・パートタイム\",\n",
    "    \"50代・自営業\",\n",
    "    \"20代・求職中\",\n",
    "    \"30代・育児休業中\"\n",
    "]\n",
    "\n",
    "# Fish Audio用マーカーリスト (プロンプト埋め込み用)\n",
    "fish_audio_markers = \"\"\"\n",
    "【基本感情】\n",
    "(angry) (sad) (excited) (surprised) (satisfied) (delighted) \n",
    "(scared) (worried) (upset) (nervous) (frustrated) (depressed) \n",
    "(empathetic) (embarrassed) (disgusted) (moved) (proud) (relaxed) \n",
    "(grateful) (confident) (interested) (curious) (confused) (joyful)\n",
    "\n",
    "【高度な感情】\n",
    "(disdainful) (unhappy) (anxious) (hysterical) (indifferent) \n",
    "(impatient) (guilty) (scornful) (panicked) (furious) (reluctant) \n",
    "(keen) (disapproving) (negative) (denying) (astonished) (serious) \n",
    "(sarcastic) (conciliative) (comforting) (sincere) (sneering) \n",
    "(hesitating) (yielding) (painful) (awkward) (amused)\n",
    "\n",
    "【トーン】\n",
    "(in a hurry tone) (shouting) (screaming) (whispering) (soft tone)\n",
    "\n",
    "【特殊効果】\n",
    "(laughing) (chuckling) (sobbing) (crying loudly) (sighing) \n",
    "(panting) (groaning) (crowd laughing) (background laughter) (audience laughing)\n",
    "\"\"\"\n",
    "\n",
    "# 話し方指示（Fish Audioタグ指定付き）\n",
    "speaking_style_data = {\n",
    "    \"よどみが多い（ためらいがち）\": \"話者Bの発話において、`(hesitating)` `(sighing)` などのタグや、フィラー（「えーと」「あのー」）を多用し、言葉に詰まる様子を表現してください。\",\n",
    "    \"普通（自然な会話）\": \"文脈に合わせて適切な【基本感情】タグを文頭に付与し、自然な会話の範囲でフィラーを含めてください。\",\n",
    "    \"スムーズ（よどみ少なめ）\": \"話者Bの発話は流暢にし、`(confident)` `(serious)` などのタグを用いて、しっかりとした口調を表現してください。\"\n",
    "}\n",
    "\n",
    "def gen_prompt_txt():\n",
    "    # ランダムに選択\n",
    "    selected_topic = random.choice(topic_list)\n",
    "    selected_situation = random.choice(situation_list)\n",
    "    selected_persona = random.choice(persona_list)\n",
    "    selected_style_name = random.choice(list(speaking_style_data.keys()))\n",
    "    selected_style_instruction = speaking_style_data[selected_style_name]\n",
    "\n",
    "    # print(\"選ばれたトピック:\", selected_topic)\n",
    "    # print(\"選ばれた状況:\", selected_situation)\n",
    "    # print(\"選ばれたペルソナ:\", selected_persona)\n",
    "    # print(\"選ばれたクライアントのスタイル:\", selected_style_name)\n",
    "\n",
    "    # 変数をプロンプトに埋め込む\n",
    "    final_prompt = prompt_template.format(\n",
    "        selected_persona=selected_persona,\n",
    "        selected_topic=selected_topic,\n",
    "        selected_situation=selected_situation,\n",
    "        selected_style_name=selected_style_name,\n",
    "        selected_style_instruction=selected_style_instruction,\n",
    "        fish_audio_markers=fish_audio_markers\n",
    "    )\n",
    "    \n",
    "    return final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d76aa80-c527-41a1-963a-5e60dc2307e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキスト対話生成関数\n",
    "async def gen_txt_dialogue():\n",
    "    prompt = gen_prompt_txt()\n",
    "    \n",
    "    resp = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n",
    "    dialogues_list = resp[\"structured_response\"].dialogues\n",
    "    return dialogues_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5813f865-a27c-473c-8acc-e8739dd606ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DEBUG\n",
    "# txt_dialogue = gen_txt_dialogue()\n",
    "# print(txt_dialogue)\n",
    "# lst_dialogue = txt_to_lst(txt_dialogue)\n",
    "# print(lst_dialogue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cd4da5-0ba6-4958-929d-c547e7c1f72c",
   "metadata": {},
   "source": [
    "## テキスト対話データを音声対話データに変換 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c975667-8174-4762-9db7-e8a602d2adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_audio_synth_prompt(text_dialogue_list):\n",
    "    resp = \"\"\n",
    "    resp_header =  \"\"\"あなたがこれから音声合成するテキストは以下の対話内容のワンフレーズです。\n",
    "この対話の文脈に合うように音声合成してください。\n",
    "\n",
    "<対話内容の全文>\"\"\"\n",
    "    resp += resp_header\n",
    "    for text_dial in text_dialogue_list:\n",
    "        resp += f\"\\n{text_dial.speaker}: {text_dial.raw_text}\"\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "568879f5-82d9-488f-a281-d3ad816f248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tokens_path = os.path.join(home_dir, \"projects/mhcc-moshi/moshi/fake.npy\")\n",
    "\n",
    "async def tts(text: str, idx: int, idx_in_dial: int, speaker: Literal[\"A\", \"B\"], prompt_text=None):\n",
    "    print(f\"[{idx}-{idx_in_dial}] の意味トークンの生成を開始します\")\n",
    "    \n",
    "    cuda_i = idx % len(cuda_devices)\n",
    "    output_dir = os.path.join(fs_tmp_path, f\"{idx}-{idx_in_dial}\")\n",
    "    cmd = f\"\"\"python /nfs1/s1f102201582/projects/fish-speech/fish_speech/models/text2semantic/inference.py --text \"{text}\" --prompt-text \"{prompt_text}\" --prompt-tokens {prompt_tokens_path} --output-dir {output_dir} --device \"cuda:{cuda_devices[cuda_i]}\" --checkpoint-path /nfs1/s1f102201582/projects/fish-speech/checkpoints/openaudio-s1-mini/ \"\"\"\n",
    "    \n",
    "    process = await asyncio.create_subprocess_shell(\n",
    "            cmd,\n",
    "            stdout=asyncio.subprocess.PIPE,\n",
    "            stderr=asyncio.subprocess.PIPE\n",
    "    )\n",
    "    stdout, stderr = await process.communicate()\n",
    "    print(f\"[{idx}-{idx_in_dial}] の意味トークンの生成が完了しました\")\n",
    "    print(f\"[{idx}-{idx_in_dial}] の音声の生成を開始します\")\n",
    "\n",
    "    semantic_path = os.path.join(output_dir, \"codes_0.npy\")\n",
    "    out_path = os.path.join(output_dir, \"fake.wav\")\n",
    "    cmd = f\"\"\"python /nfs1/s1f102201582/projects/fish-speech/fish_speech/models/dac/inference.py -i {semantic_path} --output-path {out_path} --checkpoint-path /nfs1/s1f102201582/projects/fish-speech/checkpoints/openaudio-s1-mini/codec.pth\"\"\"\n",
    "    \n",
    "    process = await asyncio.create_subprocess_shell(\n",
    "        cmd,\n",
    "        stdout=asyncio.subprocess.PIPE,\n",
    "        stderr=asyncio.subprocess.PIPE\n",
    "    )\n",
    "    stdout, stderr = await process.communicate()\n",
    "    print(f\"[{idx}-{idx_in_dial}] の音声の生成が完了しました\")\n",
    "    \n",
    "    audio, sr = librosa.load(out_path, sr=setting_sr)\n",
    "    return audio, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9df1471-cccf-40fb-bb30-23ba6fdeba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gen_audio_dialogue(idx, text_dialogue_list, prompt):\n",
    "    # 音声ファイルを順番に生成（ファイルは不要なのでwave配列で持つ）\n",
    "    wav_data = []\n",
    "    for idx_in_dial, dial in enumerate(text_dialogue_list):\n",
    "        speaker = dial.speaker\n",
    "        wav, sr = await tts(dial.tag_text, idx, idx_in_dial, speaker, prompt)\n",
    "\n",
    "        # サンプリングレートを変換\n",
    "        if sr != setting_sr:\n",
    "            # 16ビット整数のデータを、-1.0から1.0の範囲に収まる浮動小数点数に正規化\n",
    "            wav = wav.astype(np.float32) / 32768.0\n",
    "            wav = librosa.resample(wav, orig_sr=sr, target_sr=setting_sr)\n",
    "\n",
    "        # 0.3秒間の無音時間を追加\n",
    "        duration_sec = 0.3\n",
    "        num_silent_samples = int(setting_sr*duration_sec)\n",
    "        silence = np.zeros(num_silent_samples, dtype=wav.dtype)\n",
    "        wav_with_silence = np.concatenate((wav, silence))\n",
    "        wav_data.append(wav_with_silence)\n",
    "    \n",
    "    # 最終的な音声長を決定\n",
    "    max_len = sum([len(w) for w in wav_data])\n",
    "    \n",
    "    # ステレオ音声用（2チャンネル×最大長）の空配列をゼロ初期化で作成\n",
    "    stereo = np.zeros((2, max_len), dtype=np.float32)\n",
    "    \n",
    "    pos = 0\n",
    "    for i, wav in enumerate(wav_data):\n",
    "        ch = i%2  # 0:左(A), 1:右(B)\n",
    "        stereo[ch, pos:pos+len(wav)] += wav\n",
    "        pos += len(wav)\n",
    "    \n",
    "    # 転置(-1,2)する\n",
    "    stereo = stereo.T\n",
    "    return stereo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa95302-64ba-4175-ab42-4939b02ee1be",
   "metadata": {},
   "source": [
    "## mfa(montreal force alignment)による音声アラインメント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b201df8-c906-4cf7-ae5b-d94a7aa1e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def correct_json(full_text, align_json):\n",
    "    new_align_json = copy.deepcopy(align_json)\n",
    "    segments = new_align_json[\"tiers\"][\"words\"][\"entries\"]\n",
    "    checked_len = 0\n",
    "    prev_checked_len = 0\n",
    "    i = 0\n",
    "    while i < len(segments):\n",
    "        if re.search(f\"^<unk>|<sil>$\", segments[i][2]):\n",
    "            if i == 0:\n",
    "                if re.search(f\"^<unk>|<sil>$\", segments[i+1][2]):\n",
    "                    end_time = 0\n",
    "                    while re.search(f\"^<unk>|<sil>$\", segments[i+1][2]):\n",
    "                        end_time = segments[i+1][1]\n",
    "                        segments.pop(i+1)\n",
    "                    segments[i][1] = end_time\n",
    "                \n",
    "                m = re.search(f\"^(.+?){segments[i+1][2]}\", full_text[checked_len:])\n",
    "                match_text = m.groups()\n",
    "                segments[i][2] = match_text[0]\n",
    "            elif i == len(segments)-1:\n",
    "                m = re.search(f\"{segments[i-1][2]}(.+?)$\", full_text[checked_len:])\n",
    "                match_text = m.groups()\n",
    "                segments[i][2] = match_text[0]\n",
    "            else:\n",
    "                if re.search(f\"^<unk>|<sil>$\", segments[i+1][2]):\n",
    "                    end_time = 0\n",
    "                    while re.search(f\"^<unk>|<sil>$\", segments[i+1][2]):\n",
    "                        end_time = segments[i+1][1]\n",
    "                        segments.pop(i+1)\n",
    "                    segments[i][1] = end_time\n",
    "                m = re.search(f\"^{segments[i-1][2]}(.+?){segments[i+1][2]}\", full_text[prev_checked_len:])\n",
    "                match_text = m.groups()\n",
    "                segments[i][2] = match_text[0]\n",
    "        else:\n",
    "            if re.search(f\"^([。、,.!?！？…「」]){segments[i][2]}.*$\", full_text[checked_len:]):\n",
    "                m = re.search(f\"^([。、,.!?！？…「」]){segments[i][2]}.*$\", full_text[checked_len:])\n",
    "                match_punc = m.groups()\n",
    "                segments[i][2] = match_punc[0] + segments[i][2]\n",
    "            elif re.search(f\"^{segments[i][2]}([。、,.!?！？…「」]).*$\", full_text[checked_len:]):\n",
    "                m = re.search(f\"^{segments[i][2]}([。、,.!?！？…「」]).*$\", full_text[checked_len:])\n",
    "                match_punc = m.groups()\n",
    "                segments[i][2] = segments[i][2] + match_punc[0]\n",
    "                \n",
    "        prev_checked_len = checked_len\n",
    "        checked_len += len(segments[i][2])\n",
    "        i += 1\n",
    "    return new_align_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09aaef40-fca0-46e3-96b2-0c04a1ff984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfa_lock = asyncio.Lock()\n",
    "\n",
    "async def alignment_channel(channel, target_dir_name):\n",
    "    input_dir_path = join(mfa_input_dir, target_dir_name)\n",
    "    output_dir_path = join(mfa_output_dir, target_dir_name)\n",
    "    os.makedirs(input_dir_path, exist_ok=True)\n",
    "    os.makedirs(output_dir_path, exist_ok=True)\n",
    "\n",
    "    cmd = f'mfa align --quiet --overwrite --clean --final_clean --output_format json {input_dir_path} \"japanese_mfa\" {model_dir} {output_dir_path} --beam 10000 --retry_beam 40000 '\n",
    "\n",
    "    async with mfa_lock:\n",
    "        process = await asyncio.create_subprocess_shell(\n",
    "                cmd,\n",
    "                stdout=asyncio.subprocess.PIPE,\n",
    "                stderr=asyncio.subprocess.PIPE\n",
    "        )\n",
    "        stdout, stderr = await process.communicate()\n",
    "    if stderr:\n",
    "        print(\"stderr:\", stderr.decode())\n",
    "    if stdout:\n",
    "        print(\"stdout:\", stdout.decode())\n",
    "    \n",
    "    # subprocess.run([\n",
    "    #     \"mfa\",\n",
    "    #     \"align\",\n",
    "    #     input_dir_path,\n",
    "    #     \"japanese_mfa\",\n",
    "    #     model_dir,\n",
    "    #     output_dir_path,\n",
    "    #     \"--quiet\",\n",
    "    #     \"--overwrite\",\n",
    "    #     \"--clean\",\n",
    "    #     \"--final_clean\",\n",
    "    #     \"--output_format\", \"json\",\n",
    "    #     \"--beam\", \"10000\",\n",
    "    #     \"--retry_beam\", \"40000\",\n",
    "    # ])      \n",
    "\n",
    "def parse_ft_json(json_data):\n",
    "    result = {\"alignments\": []}\n",
    "\n",
    "    segments = json_data[\"tiers\"][\"words\"][\"entries\"]\n",
    "    for segment in segments:\n",
    "        result[\"alignments\"].append([\n",
    "            segment[2],\n",
    "            [segment[0], segment[1]],\n",
    "            \"SPEAKER_MAIN\"\n",
    "        ])\n",
    "    result[\"alignments\"].sort(key=lambda x: x[1][0])\n",
    "    return result\n",
    "\n",
    "def write_dialogue_text(text_dialogue_list, out_file_path):\n",
    "    oneline_text = \"\"\n",
    "    result = \"\"\n",
    "    for dial in text_dialogue_list:\n",
    "        if dial.speaker == \"A\":\n",
    "            result += dial.raw_text + \"\\n\"\n",
    "            oneline_text += dial.raw_text\n",
    "    with open(out_file_path, \"w\") as f:\n",
    "        f.write(result)\n",
    "    return oneline_text\n",
    "\n",
    "async def alignment_audio_dialogue(text_dialogue_list, audio_path, idx):\n",
    "    target_dir_name = str(idx)\n",
    "    target_dir = os.path.join(mfa_input_dir, target_dir_name)\n",
    "    if not os.path.isdir(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    target_text_file = os.path.join(target_dir, f\"{idx}.txt\")\n",
    "    oneline_text = write_dialogue_text(text_dialogue_list, target_text_file)\n",
    "\n",
    "    wav_name = f\"{idx}.wav\"\n",
    "    src_wav_path = audio_path\n",
    "    dist_wav_path = os.path.join(target_dir, wav_name)\n",
    "    shutil.copy(src_wav_path, dist_wav_path)\n",
    "\n",
    "    audio, sr = sf.read(audio_path)\n",
    "    await alignment_channel(audio[:, 0], target_dir_name)\n",
    "    \n",
    "    json_path = os.path.join(mfa_output_dir, target_dir_name, f\"{idx}.json\")\n",
    "    json_data = {}\n",
    "    with open(json_path, \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    try:\n",
    "        correct_json_data = correct_json(oneline_text, json_data)\n",
    "        ft_json = parse_ft_json(correct_json_data)\n",
    "    except:\n",
    "        print(f\"jsonファイル {idx}.json の訂正に失敗しました。\")\n",
    "        ft_json= parse_ft_json(json_data)\n",
    "    \n",
    "    return ft_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b917fe-46ac-43a6-a5e7-c9903095616a",
   "metadata": {},
   "source": [
    "## フォルダ初期化 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17a8d44f-adba-483e-9d5d-65dae116d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name():\n",
    "    wav_file_pattern = r\"^(\\d+)\\.wav$\"\n",
    "    num = -1\n",
    "    for file in os.listdir(audio_dir_path):\n",
    "        if not os.path.exists(os.path.join(audio_dir_path, file)):\n",
    "            continue\n",
    "        if not re.match(wav_file_pattern, file):\n",
    "            continue\n",
    "    \n",
    "        match_obj = re.match(wav_file_pattern, file)\n",
    "        get_number = int(match_obj.groups()[0])\n",
    "    \n",
    "        if num < get_number:\n",
    "            num = get_number\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4895d7b4-d9e6-43c3-b4b6-d21b0d4eac50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if IS_REMOVE_EXIST_FILE:\n",
    "    file_name_num = -1\n",
    "    for dir_path in data_paths:\n",
    "        delete_files(dir_path)\n",
    "else:\n",
    "    file_name_num = get_file_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535afd9-ad91-43af-a583-32cf4525864e",
   "metadata": {},
   "source": [
    "## メイン処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08b9b331-8968-42e6-b00a-590e446f7430",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processor:\n",
    "    def __init__(self, wrapped_task):\n",
    "        # 同時実行数を制限するセマフォ\n",
    "        self.sem = asyncio.Semaphore(MAX_SEMAPHORE)\n",
    "        \n",
    "        # 全体の実行可否を制御するイベント\n",
    "        self.is_healthy = asyncio.Event()\n",
    "        self.is_healthy.set()\n",
    "        \n",
    "        # リカバリー処理が重複しないようにするためのロック\n",
    "        self.recovery_lock = asyncio.Lock()\n",
    "        self.wrapped_task = wrapped_task\n",
    "\n",
    "    async def run_task(self, task_id):\n",
    "        \"\"\"個々のタスクを実行するラッパー\"\"\"\n",
    "        \n",
    "        # 1. システムが健康(is_healthy)になるまで待機\n",
    "        #    エラー発生中はここで全ての新しいタスクが止まります\n",
    "        await self.is_healthy.wait()\n",
    "\n",
    "        async with self.sem:\n",
    "            # セマフォ取得後、念のため再度チェック (待機中にエラーが起きた場合のため)\n",
    "            if not self.is_healthy.is_set():\n",
    "                await self.is_healthy.wait()\n",
    "\n",
    "            try:\n",
    "                return await self.wrapped_task(task_id)\n",
    "            except Exception as e:\n",
    "                if MAX_RETRIES <= 0:\n",
    "                    raise e\n",
    "                # エラー発生時の処理へ\n",
    "                await self.handle_error_and_retry(task_id)\n",
    "\n",
    "    async def handle_error_and_retry(self, task_id):\n",
    "        \"\"\"\n",
    "        エラー発生時のリカバリー処理。\n",
    "        他のタスクをブロックし、指数的バックオフでリトライする。\n",
    "        \"\"\"\n",
    "        # リカバリー権限を取得 (同時に複数のエラーが起きても、処理するのは1つずつ)\n",
    "        async with self.recovery_lock:\n",
    "            print(f\"--- [Stop] Task {task_id} がシステムを一時停止しました ---\")\n",
    "            \n",
    "            # 2. 全体の実行をストップ (赤信号)\n",
    "            self.is_healthy.clear()\n",
    "\n",
    "            retry_count = 1\n",
    "            while True:\n",
    "                try:\n",
    "                    # ( retry_count + 1 )^2分待つ\n",
    "                    backoff_time = ((retry_count+1)**2)*60\n",
    "                    # 指数的バックオフ待機\n",
    "                    print(f\"... Task {task_id}: リトライ待機中 ({backoff_time}s) ...\")\n",
    "                    await asyncio.sleep(backoff_time)\n",
    "\n",
    "                    # リトライ実行\n",
    "                    print(f\"--- [Retry] Task {task_id}: 再実行中 ---\")\n",
    "                    await self.wrapped_task(task_id)\n",
    "                    \n",
    "                    # 3. 成功したらブロック解除 (青信号)\n",
    "                    print(f\"--- [Resume] Task {task_id}: 成功！ システムを再開します ---\")\n",
    "                    self.is_healthy.set()\n",
    "                    break # ループを抜ける\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[x] Task {task_id}: リトライ失敗。次は {backoff_time}秒待ちます。\")\n",
    "                    if retry_count == MAX_RETRIES:\n",
    "                        raise e\n",
    "                    \n",
    "                    retry_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da82c49a-67af-4ee6-b3bb-6699f5943f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gen_dialogue(task_id):\n",
    "    print(f\"{task_id}番目のデータの生成を開始しました。\")\n",
    "    # テキスト生成\n",
    "    txt_dialogue_list = await gen_txt_dialogue()\n",
    "    \n",
    "    # 音声合成のためのプロンプト生成\n",
    "    audio_synth_prompt = build_audio_synth_prompt(txt_dialogue_list)\n",
    "    \n",
    "    # 対話テキストを音声合成\n",
    "    stereo = await gen_audio_dialogue(task_id, txt_dialogue_list, audio_synth_prompt)\n",
    "    \n",
    "    wav_name = f\"{task_id}.wav\"\n",
    "    audio_file_path = os.path.join(audio_dir_path, wav_name)\n",
    "    \n",
    "    # wavファイル出力\n",
    "    sf.write(audio_file_path, stereo, setting_sr)\n",
    "    print(f\"{task_id}番目のデータの生成が完了しました。\")\n",
    "    \n",
    "    return txt_dialogue_list, audio_file_path, task_id\n",
    "\n",
    "async def align(txt_dialogue_list, audio_file_path, i):\n",
    "    try:\n",
    "        print(f\"{i}番目のアライメントデータの生成を開始しました。\")\n",
    "        \n",
    "        # 音声アラインメント\n",
    "        json_data = await alignment_audio_dialogue(txt_dialogue_list, audio_file_path, i)\n",
    "    \n",
    "        json_name = f\"{i}.json\"\n",
    "        json_file_path = os.path.join(json_dir_path, json_name)\n",
    "        \n",
    "        # JSON出力\n",
    "        with open(json_file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(json_data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"{i}番目のアライメントデータの生成が完了しました。\")\n",
    "    except Exception as e:\n",
    "        print(f\"{i}番目のアライメントデータの生成が失敗しました。\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f5e7532-e02c-4dbe-afb8-3aef86a8d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "moc_text_dial_list = [Dialogue(speaker='A', raw_text='こんにちは。今日は、どのようなお話をしましょうか？', tag_text='(neutral)こんにちは。今日は、どのようなお話をしましょうか？'), Dialogue(speaker='B', raw_text='あ、はい。今日は、えっと、これで、あの、最終回ということなので...。なんだか、やっぱり、これで終わりかと思うと、少し寂しいような気もしてまして。', tag_text='(thinking)あ、はい。今日は、えっと、これで、あの、最終回ということなので...。なんだか、やっぱり、これで終わりかと思うと、少し寂しいような気もしてまして。'), Dialogue(speaker='B', raw_text='でも、前回お話した、こう、自分を責めてしまう気持ちとか、少しずつですけど、減ってきたような気がします。', tag_text='(sad)でも、前回お話した、こう、自分を責めてしまう気持ちとか、少しずつですけど、減ってきたような気がします。'), Dialogue(speaker='A', raw_text='うんうん。', tag_text='(listening)うんうん。'), Dialogue(speaker='A', raw_text='そうでしたね。終わりが近いと、やはり色々な気持ちが出てきますよね。ご自身を責めてしまう気持ちが減ってきたと感じられているのですね。', tag_text='(neutral)そうでしたね。終わりが近いと、やはり色々な気持ちが出てきますよね。ご自身を責めてしまう気持ちが減ってきたと感じられているのですね。'), Dialogue(speaker='B', raw_text='はい。以前は、些細なことでも「私が悪かったんだ」って、すぐに落ち込んじゃってましたから。', tag_text='(happy)はい。以前は、些細なことでも「私が悪かったんだ」って、すぐに落ち込んじゃってましたから。'), Dialogue(speaker='A', raw_text='うんうん。', tag_text='(listening)うんうん。'), Dialogue(speaker='B', raw_text='でも、ここに通い始めて、こう、自分の感情とか行動を、少し客観的に見られるようになったのが大きかったです。', tag_text='(thinking)でも、ここに通い始めて、こう、自分の感情とか行動を、少し客観的に見られるようになったのが大きかったです。'), Dialogue(speaker='A', raw_text='客観的に見られるようになった、というのは、具体的にどのような時に感じられましたか？', tag_text='(neutral)客観的に見られるようになった、というのは、具体的にどのような時に感じられましたか？'), Dialogue(speaker='B', raw_text='そうですね...。例えば、パート先でちょっとしたミスをした時とかに、前はもう、ずっと頭の中で「なんで私ってこんなにダメなんだろう」って、ぐるぐる考えてしまっていたんですけど。', tag_text='(thinking)そうですね...。例えば、パート先でちょっとしたミスをした時とかに、前はもう、ずっと頭の中で「なんで私ってこんなにダメなんだろう」って、ぐるぐる考えてしまっていたんですけど。'), Dialogue(speaker='A', raw_text='うんうん。', tag_text='(listening)うんうん。'), Dialogue(speaker='B', raw_text='最近は、「あ、これはミスしたけど、次は気をつけよう」って、ちょっと切り替えができるようになってきたというか。', tag_text='(neutral)最近は、「あ、これはミスしたけど、次は気をつけよう」って、ちょっと切り替えができるようになってきたというか。'), Dialogue(speaker='A', raw_text='なるほど。その「切り替えができるようになった」というのは、Bさんにとって大きな変化だったのですね。', tag_text='(neutral)なるほど。その「切り替えができるようになった」というのは、Bさんにとって大きな変化だったのですね。'), Dialogue(speaker='B', raw_text='はい、本当に。以前は、もう、そのミスしたこと自体で、一日の気分が台無しになってしまっていたので。', tag_text='(happy)はい、本当に。以前は、もう、そのミスしたこと自体で、一日の気分が台無しになってしまっていたので。'), Dialogue(speaker='A', raw_text='うんうん。', tag_text='(listening)うんうん。'), Dialogue(speaker='A', raw_text='ご自身の変化を実感されているのですね。素晴らしいことです。', tag_text='(neutral)ご自身の変化を実感されているのですね。素晴らしいことです。'), Dialogue(speaker='B', raw_text='でも、まだ、こう、たまに、本当に些細なことで、「あー、また私、やってしまった」って、一瞬だけですけど、やっぱりそう思ってしまうこともあって...。', tag_text='(thinking)でも、まだ、こう、たまに、本当に些細なことで、「あー、また私、やってしまった」って、一瞬だけですけど、やっぱりそう思ってしまうこともあって...。'), Dialogue(speaker='A', raw_text='うんうん。', tag_text='(listening)うんうん。'), Dialogue(speaker='A', raw_text='そうですよね。完全にゼロにするというのは、なかなか難しいことかもしれませんね。', tag_text='(neutral)そうですよね。完全にゼロにするというのは、なかなか難しいことかもしれませんね。'), Dialogue(speaker='B', raw_text='はい。だから、これからも、こう、自分で、あの、考えすぎないように、気をつけなきゃなって思ってます。', tag_text='(neutral)はい。だから、これからも、こう、自分で、あの、考えすぎないように、気をつけなきゃなって思ってます。'), Dialogue(speaker='A', raw_text='ご自身で、その考え方と上手に付き合っていく方法を見つけられているのですね。', tag_text='(neutral)ご自身で、その考え方と上手に付き合っていく方法を見つけられているのですね。'), Dialogue(speaker='B', raw_text='はい。先生と話していく中で、こう、「完璧じゃなくてもいいんだ」って思えるようになったのが、すごく、大きくて。', tag_text='(happy)はい。先生と話していく中で、こう、「完璧じゃなくてもいいんだ」って思えるようになったのが、すごく、大きくて。'), Dialogue(speaker='A', raw_text='うんうん。', tag_text='(listening)うんうん。'), Dialogue(speaker='A', raw_text='「完璧じゃなくてもいいんだ」という気づきは、Bさんにとって、どのような意味がありましたか？', tag_text='(neutral)「完璧じゃなくてもいいんだ」という気づきは、Bさんにとって、どのような意味がありましたか？'), Dialogue(speaker='B', raw_text='なんだか、肩の力が抜けた、というか...。全部を一人で抱え込まなくてもいいんだって、少し楽になれた気がします。', tag_text='(relief)なんだか、肩の力が抜けた、というか...。全部を一人で抱え込まなくてもいいんだって、少し楽になれた気がします。'), Dialogue(speaker='A', raw_text='それは良かったです。これからの生活の中で、また悩むことが出てきたとしても、今、Bさんが得られたその感覚を思い出して、ご自身を大切にしてくださいね。', tag_text='(neutral)それは良かったです。これからの生活の中で、また悩むことが出てきたとしても、今、Bさんが得られたその感覚を思い出して、ご自身を大切にしてくださいね。'), Dialogue(speaker='B', raw_text='はい...。本当に、ありがとうございました。最初は、まさか自分がカウンセリングに来るなんて思ってもみなくて...。', tag_text='(sad)はい...。本当に、ありがとうございました。最初は、まさか自分がカウンセリングに来るなんて思ってもみなくて...。'), Dialogue(speaker='A', raw_text='うんうん。', tag_text='(listening)うんうん。'), Dialogue(speaker='B', raw_text='でも、本当に来て良かったです。先生のおかげで、少し前向きになれました。', tag_text='(neutral)でも、本当に来て良かったです。先生のおかげで、少し前向きになれました。'), Dialogue(speaker='A', raw_text='Bさんが、ご自身のペースで、前向きに進んでいかれることを、私も応援しています。また何かありましたら、いつでも頼ってくださいね。', tag_text='(happy)Bさんが、ご自身のペースで、前向きに進んでいかれることを、私も応援しています。また何かありましたら、いつでも頼ってくださいね。'), Dialogue(speaker='B', raw_text='はい！ ありがとうございます。', tag_text='(happy)はい！ ありがとうございます。')]\n",
    "\n",
    "moc_audio_file_path = join(\"/users/s1f102201582/projects/mhcc-moshi/moshi/data/mock/data_stereo/0.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b705025-d449-46b3-b462-558e147774e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gen_dialogueのモック\n",
    "# async def gen_dialogue(task_id):\n",
    "#     wav_name = f\"{task_id}.wav\"\n",
    "#     audio_file_path = os.path.join(audio_dir_path, wav_name)\n",
    "#     shutil.copy(moc_audio_file_path, audio_file_path)\n",
    "\n",
    "#     return moc_text_dial_list, audio_file_path, task_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e63b5640-45bb-49e6-92a1-eb78f8f33b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gen_data(task_id):\n",
    "    text_dial_list, audio_file_path, task_id = await gen_dialogue(task_id)\n",
    "    return await align(text_dial_list, audio_file_path, task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff007233-9811-4750-9a96-2f8b9005279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    processor = Processor(gen_data)\n",
    "    all_tasks = []\n",
    "    \n",
    "    for i in range(file_name_num+1, gen_dial_num+file_name_num+1):\n",
    "        cor = processor.run_task(i)\n",
    "        task = asyncio.create_task(cor)\n",
    "        all_tasks.append(task)\n",
    "    await asyncio.gather(*all_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8f14e93-697f-4455-808d-ac9523190edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:31:37] asyncio.run(main()) を呼び出します\n",
      "0番目のアライメントデータの生成を開始しました。\n",
      "stderr: \u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Setting up corpus information\u001b[33m...\u001b[0m                                      \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Loading corpus from source files\u001b[33m...\u001b[0m                                   \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Found \u001b[1;36m1\u001b[0m speaker across \u001b[1;36m1\u001b[0m file, average number of utterances per       \n",
      "\u001b[2;36m \u001b[0m         speaker: \u001b[1;36m1.0\u001b[0m                                                          \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Initializing multiprocessing jobs\u001b[33m...\u001b[0m                                  \n",
      "\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m Number of jobs was specified as \u001b[1;36m3\u001b[0m, but due to only having \u001b[1;36m1\u001b[0m speakers, \n",
      "\u001b[2;36m \u001b[0m         MFA will only use \u001b[1;36m1\u001b[0m jobs. Use the --single_speaker flag if you would  \n",
      "\u001b[2;36m \u001b[0m         like to split utterances across jobs regardless of their speaker.     \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Normalizing text\u001b[33m...\u001b[0m                                                   \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Generating MFCCs\u001b[33m...\u001b[0m                                                   \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Calculating CMVN\u001b[33m...\u001b[0m                                                   \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Generating final features\u001b[33m...\u001b[0m                                          \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Creating corpus split\u001b[33m...\u001b[0m                                              \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Compiling training graphs\u001b[33m...\u001b[0m                                          \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Performing first-pass alignment\u001b[33m...\u001b[0m                                    \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Generating alignments\u001b[33m...\u001b[0m                                              \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Collecting phone and word alignments from alignment lattices\u001b[33m...\u001b[0m       \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Analyzing alignment quality\u001b[33m...\u001b[0m                                        \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Exporting alignment TextGrids to                                      \n",
      "\u001b[2;36m \u001b[0m         \u001b[35m/users/s1f102201582/projects/mhcc-moshi/moshi/data/fs/v2/temp/mfa_outp\u001b[0m\n",
      "\u001b[2;36m \u001b[0m         \u001b[35mut/\u001b[0m\u001b[95m0...\u001b[0m                                                               \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Finished exporting TextGrids to                                       \n",
      "\u001b[2;36m \u001b[0m         \u001b[35m/users/s1f102201582/projects/mhcc-moshi/moshi/data/fs/v2/temp/mfa_outp\u001b[0m\n",
      "\u001b[2;36m \u001b[0m         \u001b[35mut/\u001b[0m\u001b[95m0\u001b[0m!                                                                 \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Done! Everything took \u001b[1;36m257.642\u001b[0m seconds                                 \n",
      "\n",
      "0番目のアライメントデータの生成が完了しました。\n",
      "[13:36:09] asyncio.run() が終了しました (実行時間: 271.70s)\n"
     ]
    }
   ],
   "source": [
    "print(f\"[{time.strftime('%X')}] asyncio.run(main()) を呼び出します\")\n",
    "start_run = time.time()\n",
    "await main()\n",
    "end_run = time.time()\n",
    "print(f\"[{time.strftime('%X')}] asyncio.run() が終了しました (実行時間: {end_run - start_run:.2f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4026acb9-7e96-4d71-b8e4-eda9635150d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f58461e-22c2-4331-8b78-45cd9e0cb862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
