{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f300fa64-76a0-4e92-91b9-c1cdffaabed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "import ast\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "# .envファイル読み込み\n",
    "load_dotenv(\"/users/s1f102201582/projects/mhcc-moshi/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ff65676-e41a-4456-84dc-acf221d8dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "from os.path import join, expanduser\n",
    "\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "BASE_URL = \"https://api.openai.iniad.org/api/v1\"\n",
    "MODEL='gemini-2.5-flash'\n",
    "TEMPERATURE = 1.0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,4\"\n",
    "\n",
    "# 生成する音声のサンプリングレート\n",
    "setting_sr = 16000\n",
    "\n",
    "#対話音声データの個数を指定\n",
    "gen_dial_num = 1000\n",
    "\n",
    "# すでに作成した対話データを削除するかどうか\n",
    "IS_REMOVE_EXIST_FILE = True\n",
    "\n",
    "# ftに使うjsonとaudioの出力フォルダパス\n",
    "home_dir = expanduser(\"~\")\n",
    "json_dir_path = join(home_dir, \"projects/mhcc-moshi/moshi/data/v1/data_stereo\")\n",
    "audio_dir_path = join(home_dir, \"projects/mhcc-moshi/moshi/data/v1/data_stereo\")\n",
    "\n",
    "# mfa関連のパス\n",
    "model_dir = join(home_dir, \"Documents/MFA/pretrained_models/acoustic/japanese_mfa.zip\")\n",
    "mfa_input_dir = join(home_dir, \"projects/mhcc-moshi/moshi/data/v1/mfa_input\")\n",
    "mfa_output_dir = join(home_dir, \"projects/mhcc-moshi/moshi/data/v1/mfa_output\")\n",
    "\n",
    "#RAGで読み取るPDFのパス\n",
    "rag_pdf_dir = join(home_dir, \"projects/mhcc-moshi/mental_docs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c53cf1a5-40ad-4c9b-99b6-3fd2be42010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_paths = [\n",
    "    json_dir_path,\n",
    "    audio_dir_path,\n",
    "    mfa_input_dir,\n",
    "    mfa_output_dir,\n",
    "]\n",
    "\n",
    "for p in base_paths:\n",
    "    if not os.path.isdir(p):\n",
    "        os.makedirs(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d49bf16-cba9-4d2f-845e-eaccdaeeb1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model定義\n",
    "model = ChatGoogleGenerativeAI(\n",
    "                 model=MODEL,\n",
    "                 temperature=TEMPERATURE)\n",
    "\n",
    "# 埋め込みモデル定義\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    openai_api_base=BASE_URL,\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "# データベース定義\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"collection\",\n",
    "    embedding_function=embeddings,\n",
    "    # persist_directory = \"/path/to/db_file\" # if necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32c95503-a152-474b-9e08-f073a90a9e11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                     | 0/3 [00:00<?, ?it/s]Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(\n",
    "    rag_pdf_dir,\n",
    "    glob=\"*.pdf\",\n",
    "    show_progress=True,\n",
    "    loader_cls=PDFMinerLoader,\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"Loaded {len(docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e927955-3b0a-4ef1-a378-3a6fddfc387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#読み込んだ文章データをオーバーラップ200文字で1000文字づつ分割\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True, # 分割前の文章のインデックスを追跡\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# データベースにデータを追加\n",
    "document_ids = vector_store.add_documents(documents=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "557b487e-8ab0-42e4-8ee9-a6da27adc4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1].text\n",
    "    retrieved_docs = vector_store.similarity_search(last_query, k=2)\n",
    "\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. Use the following context in your response:\"\n",
    "        f\"\\n\\n{docs_content}\"\n",
    "    )\n",
    "\n",
    "    return system_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed9c24eb-5d13-4b58-8816-90646abceaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Dialogue(BaseModel):\n",
    "    \"\"\"対話データを構成する対話クラス\"\"\"\n",
    "    speaker: Literal[\"A\", \"B\"] = Field(..., description=\"話者。Aはカウンセラー、Bはクライエントを表す。\")\n",
    "    raw_text: str = Field(..., description=\"FishAudioタグなしの話者が話した内容。\")\n",
    "    tag_text: str = Field(..., description=\"FishAudioタグありの話者が話した内容。\")\n",
    "\n",
    "class Dialogues(BaseModel):\n",
    "    \"\"\"カウンセリングを目的としたカウンセリング対話データ\"\"\"\n",
    "    dialogues: list[Dialogue] = Field(..., description=\"対話データを構成する対話クラスのリスト。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c26f53b-2ff1-4a22-acde-70c8ede55918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "agent = create_agent(\n",
    "    model, \n",
    "    tools=[],\n",
    "    middleware=[prompt_with_context],\n",
    "    response_format=ToolStrategy(\n",
    "        Dialogues,\n",
    "        handle_errors=\"フォーマットに合うように、もう一度対話データを生成してください。\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85a17357-351a-4182-b633-40e4821891b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#promptを作成\n",
    "import random\n",
    "\n",
    "prompt_template = \"\"\"あなたは、Fish Audioによる音声合成（TTS）用の対話シナリオを作成するプロのライターです。\n",
    "以下の【要件】、【設定】、そして【指示】に従い、対話データ（Dialogues）を生成してください。\n",
    "\n",
    "### 【目的】\n",
    "メンタルヘルスケアのカウンセリング対話をシミュレーションします。\n",
    "\n",
    "### 【出力データ構造の定義】\n",
    "* **speaker**: \"A\" (カウンセラー) または \"B\" (クライエント)\n",
    "* **tag_text**: 文頭に必ずFish Audio用マーカー（例: `(sad)`) を付与したテキスト。\n",
    "* **raw_text**: `tag_text`からマーカーを削除した純粋なテキスト。\n",
    "\n",
    "### 【最重要要件：自然な会話の再現】\n",
    "1.  **短いターン:** 一度の発話は短く区切る。長い独白は禁止。\n",
    "2.  **インターラプト:** Bが長く話そうとしたら、Aが「(listening)うんうん」と短い相槌で挟む。\n",
    "3.  **タグの使用:** 文頭に必ずタグをつける。\n",
    "\n",
    "### 【禁止事項】\n",
    "* **プレースホルダーの禁止:** テキスト中に「〇〇さん」「××さん」のような伏せ字・プレースホルダーを含めることは**厳禁**です。\n",
    "* **カウンセラーの「知ったかぶり」禁止:** カウンセラー(A)が、クライアント(B)が口にする前に、前回の内容や宿題について言及することを禁止します。文脈は必ずBの発言によって作ってください。\n",
    "\n",
    "### 【指示】\n",
    "\n",
    "1.  **会話の開始と導入フェーズ（最重要）:**\n",
    "    * **基本ルール:** カウンセラー(A)は、クライアント(B)の現在の状況や前回の詳細を**忘れている/知らない**ものとして振る舞ってください。\n",
    "    \n",
    "    * **状況が「初回」の場合:**\n",
    "        * A: まず**名前**を尋ねる。 -> B: **具体的な苗字**（佐藤、鈴木など）を名乗る。\n",
    "        * A: 「今日はどのようなことでお見えになりましたか？」と**来談理由**を尋ねる。\n",
    "        * B: 指定された**【トピック】**についての悩みを話し始める。\n",
    "        \n",
    "    * **状況が「初回」以外の場合:**\n",
    "        * A: 名前は呼ばずに挨拶し、「前回からいかがですか？」や「今日はどのようなお話をしましょうか？」と**完全にオープンな質問**をする。（※「宿題はどうでしたか？」などとAから特定の話題を振ることは禁止）。\n",
    "        * B: Aの質問に答える形で、**【トピック】**や**【状況】**（宿題があったことや、前回の続きなど）を**自分から説明する**。\n",
    "        * A: Bの説明を聞いて初めて、「ああ、そうでしたね」や「なるほど、そういう状況なのですね」と状況を把握・確認する。\n",
    "\n",
    "    * **共通事項:**\n",
    "        * AがBの話を聞いて状況を把握した**後**に、初めて具体的なカウンセリングへ移行してください。\n",
    "        * 導入のヒアリング段階であっても、「短いターン」と「インターラプト」のルールは守ってください。\n",
    "\n",
    "2.  **設定:**\n",
    "    * クライアント(B)のペルソナ: {selected_persona}\n",
    "    * トピック: {selected_topic}\n",
    "    * 状況: {selected_situation}\n",
    "    * 話し方指示: {selected_style_instruction}\n",
    "\n",
    "3.  **会話の構成:**\n",
    "    * 会話量は **4分程度** を目安とし、**25〜35往復（ターン）** 程度生成してください。\n",
    "    * ペルソナの背景（年齢・職業）を反映させる（直接言わせず、内容で匂わせる）。\n",
    "    * クライアント(B)の話し方指示（よどみ具合など）を忠実に守る。\n",
    "\n",
    "出力は指定された `Dialogues` スキーマに従ってください。\n",
    "\"\"\"\n",
    "\n",
    "# トピックリスト（悩みの種類）(全40項目)\n",
    "topic_list = [\n",
    "  # 仕事・キャリア関連\n",
    "  \"仕事のプレッシャーや過労、バーンアウト\",\n",
    "  \"職場の人間関係（上司、同僚、部下）\",\n",
    "  \"キャリアプランの悩み、キャリアチェンジの不安\",\n",
    "  \"転職・就職活動のストレス\",\n",
    "  \"ハラスメント（パワハラ、モラハラなど）の影響\",\n",
    "  \"仕事へのモチベーション低下、やる気が出ない\",\n",
    "\n",
    "  # 自己認識・感情関連\n",
    "  \"自己肯定感の低さ、自分を責めてしまう\",\n",
    "  \"完璧主義、失敗への過度な恐れ\",\n",
    "  \"他人の評価が過度に気になる、承認欲求\",\n",
    "  \"劣等感（他人との比較）\",\n",
    "  \"自分のやりたいことが分からない、アイデンティティの悩み\",\n",
    "  \"感情のコントロールが難しい（怒り、イライラ、悲しみ）\",\n",
    "  \"ネガティブ思考の癖、反芻思考（同じことをぐるぐる考えてしまう）\",\n",
    "  \"焦燥感、何かに追われている感覚\",\n",
    "  \"罪悪感（休むことへの罪悪感など）\",\n",
    "  \"虚無感、むなしさ、生きがいを感じられない\",\n",
    "  \"趣味や楽しみを感じられない（アンヘドニア）\",\n",
    "  \n",
    "  # 対人関係\n",
    "  \"家族関係（親子、夫婦、兄弟、親戚）\",\n",
    "  \"友人関係や恋愛関係の悩み\",\n",
    "  \"コミュニケーションへの苦手意識（雑談、会議での発言など）\",\n",
    "  \"人に頼ることができない、甘えられない\",\n",
    "  \"他人の期待に応えすぎようとしてしまう（ピープルプリーザー）\",\n",
    "  \"境界線（バウンダリー）の問題（NOと言えない）\",\n",
    "  \"孤独感、疎外感\",\n",
    "  \"HSP（繊細さ）に関する悩み\",\n",
    "  \n",
    "  # 生活・健康関連\n",
    "  \"将来への漠然とした不安\",\n",
    "  \"気分の落ち込み、無気力\",\n",
    "  \"睡眠に関する悩み（寝付けない、途中で起きる、過眠）\",\n",
    "  \"生活リズムの乱れ\",\n",
    "  \"体調不良（頭痛、倦怠感、腹痛など）と気分の関連\",\n",
    "  \"健康不安（病気への過度な心配）\",\n",
    "\n",
    "  # 習慣・行動関連\n",
    "  \"決断疲れ、何かを選ぶことができない\",\n",
    "  \"先延ばし癖、物事が始められない\",\n",
    "  \"SNS疲れ、デジタルデトックスの必要性\",\n",
    "\n",
    "  # 特定の出来事\n",
    "  \"ライフイベント（引っ越し、結婚、出産、育児、介護）に伴うストレス\",\n",
    "  \"特定の出来事による軽いトラウマやフラッシュバック\",\n",
    "  \"喪失体験（別れ、死別）からの回復（グリーフケア）\",\n",
    "  \"過去の選択への後悔\"\n",
    "]\n",
    "\n",
    "# 状況リスト（セッションの場面）\n",
    "situation_list = [\n",
    "  \"初回\",\n",
    "  \"初期\",\n",
    "  \"中期（深掘り）\",\n",
    "  \"中期（宿題の確認）\",\n",
    "  \"中期（感情の表出）\",\n",
    "  \"後期\",\n",
    "  \"終了（終結）\"\n",
    "]\n",
    "\n",
    "# クライアントのペルソナリスト（年齢と職業/立場のみ）\n",
    "persona_list = [\n",
    "    \"20代・会社員\",\n",
    "    \"30代・会社員\",\n",
    "    \"40代・会社員\",\n",
    "    \"50代・会社員\",\n",
    "    \"20代・大学生\",\n",
    "    \"20代・大学院生\",\n",
    "    \"30代・管理職\",\n",
    "    \"40代・主婦/主夫\",\n",
    "    \"30代・フリーランス\",\n",
    "    \"20代・アルバイト\",\n",
    "    \"40代・パートタイム\",\n",
    "    \"50代・自営業\",\n",
    "    \"20代・求職中\",\n",
    "    \"30代・育児休業中\"\n",
    "]\n",
    "\n",
    "# Fish Audio用マーカーリスト (プロンプト埋め込み用)\n",
    "fish_audio_markers = \"\"\"\n",
    "【基本感情】\n",
    "(angry) (sad) (excited) (surprised) (satisfied) (delighted) \n",
    "(scared) (worried) (upset) (nervous) (frustrated) (depressed) \n",
    "(empathetic) (embarrassed) (disgusted) (moved) (proud) (relaxed) \n",
    "(grateful) (confident) (interested) (curious) (confused) (joyful)\n",
    "\n",
    "【高度な感情】\n",
    "(disdainful) (unhappy) (anxious) (hysterical) (indifferent) \n",
    "(impatient) (guilty) (scornful) (panicked) (furious) (reluctant) \n",
    "(keen) (disapproving) (negative) (denying) (astonished) (serious) \n",
    "(sarcastic) (conciliative) (comforting) (sincere) (sneering) \n",
    "(hesitating) (yielding) (painful) (awkward) (amused)\n",
    "\n",
    "【トーン】\n",
    "(in a hurry tone) (shouting) (screaming) (whispering) (soft tone)\n",
    "\n",
    "【特殊効果】\n",
    "(laughing) (chuckling) (sobbing) (crying loudly) (sighing) \n",
    "(panting) (groaning) (crowd laughing) (background laughter) (audience laughing)\n",
    "\"\"\"\n",
    "\n",
    "# 話し方指示（Fish Audioタグ指定付き）\n",
    "speaking_style_data = {\n",
    "    \"よどみが多い（ためらいがち）\": \"話者Bの発話において、`(hesitating)` `(sighing)` などのタグや、フィラー（「えーと」「あのー」）を多用し、言葉に詰まる様子を表現してください。\",\n",
    "    \"普通（自然な会話）\": \"文脈に合わせて適切な【基本感情】タグを文頭に付与し、自然な会話の範囲でフィラーを含めてください。\",\n",
    "    \"スムーズ（よどみ少なめ）\": \"話者Bの発話は流暢にし、`(confident)` `(serious)` などのタグを用いて、しっかりとした口調を表現してください。\"\n",
    "}\n",
    "\n",
    "def gen_prompt_txt():\n",
    "    # ランダムに選択\n",
    "    selected_topic = random.choice(topic_list)\n",
    "    selected_situation = random.choice(situation_list)\n",
    "    selected_persona = random.choice(persona_list)\n",
    "    selected_style_name = random.choice(list(speaking_style_data.keys()))\n",
    "    selected_style_instruction = speaking_style_data[selected_style_name]\n",
    "\n",
    "    print(\"選ばれたトピック:\", selected_topic)\n",
    "    print(\"選ばれた状況:\", selected_situation)\n",
    "    print(\"選ばれたペルソナ:\", selected_persona)\n",
    "    print(\"選ばれたクライアントのスタイル:\", selected_style_name)\n",
    "\n",
    "    # 変数をプロンプトに埋め込む\n",
    "    final_prompt = prompt_template.format(\n",
    "        selected_persona=selected_persona,\n",
    "        selected_topic=selected_topic,\n",
    "        selected_situation=selected_situation,\n",
    "        selected_style_name=selected_style_name,\n",
    "        selected_style_instruction=selected_style_instruction,\n",
    "        fish_audio_markers=fish_audio_markers\n",
    "    )\n",
    "    \n",
    "    return final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3bb9d1c-1e99-442b-9e46-536bf44034a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキスト対話生成関数\n",
    "def gen_txt_dialogue():\n",
    "    prompt = gen_prompt_txt()\n",
    "    resp = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n",
    "    dialogues_list = resp[\"structured_response\"].dialogues\n",
    "    return dialogues_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8e85210-9c0a-4916-a914-efcef9ef001a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "選ばれたトピック: 特定の出来事による軽いトラウマやフラッシュバック\n",
      "選ばれた状況: 初期\n",
      "選ばれたペルソナ: 50代・自営業\n",
      "選ばれたクライアントのスタイル: よどみが多い（ためらいがち）\n",
      "\n",
      "\n",
      "A: (gentle)こんにちは。今日はどのようなことでお見えになりましたか？\n",
      "B: (hesitating)あのー、田中と申します。最近ちょっと、えー、困っていることがありまして...\n",
      "A: (calm)田中さん、そうでしたか。具体的には、どのようなことでしょうか？\n",
      "B: (sighing)ええと、半年前くらいに、ちょっと、仕事で大きな問題がありまして。それから、時々、あの時のことを思い出して、急に不安になるんです。\n",
      "A: (listening)うんうん。\n",
      "B: (nervous)特に、その、お金関係の計算をしている時とかに、急に、えー、動悸がしてしまって。\n",
      "A: (calm)お金関係の計算をしている時に、動悸がするのですね。\n",
      "B: (hesitating)はい。あの時、本当に、えー、自営業なので、もう全てを失うんじゃないかと...思ってしまって。\n",
      "A: (listening)うんうん。\n",
      "B: (sighing)それが、急に、こう、フラッシュバックするような感じで、心臓がドキドキして、手も震えてきたりするんです。\n",
      "A: (understanding)フラッシュバックして、心臓がドキドキして、手も震えるのですね。\n",
      "B: (nervous)ええ。その、何て言うか、もう、息苦しくなってしまうこともあって...\n",
      "A: (empathic)息苦しくなるほど、ですか。それは、大変お辛いですね。\n",
      "B: (worried)はい...もう、どうしていいか分からなくて...\n",
      "A: (calm)その動悸や手の震えは、具体的にどのような状況で起こることが多いですか？\n",
      "B: (thinking)ええと、例えば、パソコンで経理ソフトを開いて、請求書を入力している時とか。\n",
      "A: (listening)うんうん。\n",
      "B: (hesitating)あとは、あのー、銀行の通帳を記帳しに行った時なんかも、ちょっと、足がすくんでしまったり。\n",
      "A: (understanding)経理ソフトの入力中や、銀行で記帳する時ですね。\n",
      "B: (sighing)はい。普段は何でもないことなのに、急に、こう、あの時の嫌な感じが蘇ってきて...\n",
      "A: (calm)その嫌な感じが蘇る、というのは、他に何か具体的な感覚がありますか？\n",
      "B: (nervous)ええと、視界が、こう、一瞬、真っ暗になるような...気がする時もあって。\n",
      "A: (gentle)視界が真っ暗に。\n",
      "B: (worried)はい。それが、あの、また起きるんじゃないかって、すごく不安で...\n",
      "A: (calm)その不安な気持ちが、日常生活や、お仕事に何か影響を与えていますか？\n",
      "B: (hesitating)あのー、正直、少し影響が出ていますね。集中力が続かなくなって、作業の効率が落ちたり...\n",
      "A: (listening)うんうん。\n",
      "B: (worried)自営業なので、その、それが長引くと、ちょっと、えー、経営にも関わるので、何とかしたいな、と。\n",
      "A: (understanding)そうでしたか。それは大変お困りでしょうね。今日はお話しいただきありがとうございます。その具体的な状況について、もう少し詳しくお聞かせいただけますか？\n"
     ]
    }
   ],
   "source": [
    "dialogues_list = gen_txt_dialogue()\n",
    "print(\"\\n\")\n",
    "for dial in dialogues_list:\n",
    "    print(f\"{dial.speaker}: {dial.tag_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28240a-7c1c-47ec-a673-c6571673c94a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
